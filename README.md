# Self-Attention（pytorch实现）
**OneHead-Attention文件夹**下是单头自注意力机制的实现(无Mask)  
**MultiHead-Attention文件夹**下是多头自注意力机制的实现(无Mask)  
**Encoder文件夹**下是Ecoder编码器的完整实现（有mask）  
### Decoder部分后续补充。。。
